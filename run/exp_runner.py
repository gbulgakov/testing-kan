import sys
import os
from pathlib import Path

HOME = str(Path.home())
sys.path.append(os.path.join(HOME, 'KAN', 'testing-kan'))

import torch.nn as nn
import numpy as np
from typing import Literal, Optional
import pandas as pd
import numpy as np
import pickle
import wandb
from IPython.display import clear_output
wandb.login(key='936d887040f82c8da3d87f5207c4178259c7b922')

from project_utils import utils
from project_utils import datasets
from project_utils.tg_bot import send_telegram_file, send_telegram_message
from project_utils.wandb_tuning import wandb_tuning
from project_utils.wandb_testing import test_best_model

from functools import wraps
import traceback
from datetime import datetime

def telegram_error_notification(func):
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—à–∏–±–æ–∫ –≤ Telegram"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–¥—Ä–æ–±–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            error_msg = (
                f"*‚ùå –û—à–∏–±–∫–∞*\n\n"
                f"*Model:* `{kwargs.get('model_name', 'N/A')}`\n"
                f"*Dataset:* `{kwargs.get('dataset_name', 'N/A')}`\n"
                f"*Arch type:* `{kwargs.get('arch_type', 'N/A')}`\n"
                f"*Embedding:* `{kwargs.get('emb_name', 'N/A')}`\n"
                f"*Optimizer:* `{kwargs.get('optim_name', 'N/A')}`\n"
                f"*–§—É–Ω–∫—Ü–∏—è:* `{func.__name__}`\n\n"
                f"*–û—à–∏–±–∫–∞:*\n```\n{str(e)}\n```\n\n"
                f"*Traceback:* (–Ω–∞–∂–º–∏—Ç–µ ‚ñ∂Ô∏è)\n"
                f"```\n{traceback.format_exc()}\n```"
            )
            send_telegram_message(error_msg)
            raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–∞–ª—å—à–µ
    return wrapper


def run_single_model(project_name, dataset_name, model_name, arch_type, emb_name, optim_name, dataset, num_epochs, num_trials, patience):
    sweep_id = wandb_tuning(project_name, dataset_name, model_name, arch_type, emb_name, optim_name, dataset, num_epochs, num_trials, patience)
    clear_output(wait=True)
    # –≤—Å–ø–æ–º–∏–Ω–∞–µ–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    api = wandb.Api()
    sweep = api.sweep(f'georgy-bulgakov/{project_name}/{sweep_id}')
    runs = sweep.runs

    if dataset['info']['task_type'] == 'regression':
        best_run = min(runs, key=lambda run: run.summary.get('val_loss', float('inf')))
    else:
        best_run = max(runs, key=lambda run: run.summary.get('val_acc', 0))
    best_params = best_run.config

    stats = test_best_model(best_params, project_name, dataset_name, model_name, arch_type, emb_name, optim_name, dataset, num_epochs, patience)
    return stats

def run_single_dataset(project_name, dataset_name, 
                       optim_names, emb_names, model_names, arch_types,
                       num_epochs, num_trials, patience):
    # dataset_type = dataset_info['type']
    zip_path = os.path.join(HOME, 'KAN', 'data', f'{dataset_name}.zip')
    dataset = datasets.load_dataset(dataset_name, zip_path)
    pkl_logs = {}

    for model_name in model_names:
        for arch_type in arch_types:
            for optim_name in optim_names:
                for emb_name in emb_names:
                    stats = run_single_model(project_name, dataset_name, model_name, arch_type, emb_name, optim_name, dataset, num_epochs, num_trials, patience)
                    clear_output(wait=True)
                    pkl_logs[f'{model_name}_{arch_type}_{emb_name}_{optim_name}'] = stats
                    # send_telegram_message(f'‚úÖ {model_name}_{arch_type}_{emb_name}_{optim_name} finished on {dataset_name}\
                    #                       Test sweep_id {stats["sweep_id"]}')

    # with open(f'/home/no_prolactin/KAN/testing-kan/results/{dataset_name}.pkl', 'wb') as f:
    #     pickle.dump(pkl_logs, f)

    # send_telegram_file(f'/home/no_prolactin/KAN/testing-kan/results/{dataset_name}.pkl')
    return pkl_logs


def run_experiment(
    *,
    project_name,
    dataset_names,
    model_names,
    emb_names,
    optim_names,
    arch_types,
    num_epochs,
    num_trials,
    patience,
    exp_name
):
    send_telegram_message(
        f"üöÄ *–ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞*\n"
        f"‚ñ´Ô∏è *–ù–∞–∑–≤–∞–Ω–∏–µ:* `{exp_name}`\n"
        f"‚ñ´Ô∏è *–í—Ä–µ–º—è:* `{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}`"
    )
    total_logs = {}
    results_dir = os.path.join(HOME, 'KAN', 'testing-kan', 'results')

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç
    os.makedirs(results_dir, exist_ok=True)
    for dataset_name in dataset_names:
        logs = run_single_dataset(
                project_name=project_name,
                dataset_name=dataset_name,
                optim_names=optim_names,
                emb_names=emb_names,
                model_names=model_names,
                arch_types=arch_types,
                num_epochs=num_epochs,
                num_trials=num_trials,
                patience=patience
              )
        total_logs[dataset_name] = logs
        # send_telegram_message(f'‚úÖ Finished on {dataset_name}')

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–º –ø—É—Ç–µ–º
    results_path = os.path.join(results_dir, f'{exp_name}.pkl')
    with open(results_path, 'wb') as f:
        pickle.dump(total_logs, f)

    # send_telegram_message(f'‚úÖ Finished {exp_name}')
    send_telegram_file(results_path)
    return total_logs

