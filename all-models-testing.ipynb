{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-14T21:39:36.906650Z",
     "iopub.status.busy": "2025-04-14T21:39:36.906425Z",
     "iopub.status.idle": "2025-04-14T21:41:00.841219Z",
     "shell.execute_reply": "2025-04-14T21:41:00.840248Z",
     "shell.execute_reply.started": "2025-04-14T21:39:36.906633Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting delu\n",
      "  Downloading delu-0.0.26-py3-none-any.whl.metadata (805 bytes)\n",
      "Requirement already satisfied: numpy<3,>=1.21 in /usr/local/lib/python3.11/dist-packages (from delu) (1.26.4)\n",
      "Requirement already satisfied: torch<3,>=1.9 in /usr/local/lib/python3.11/dist-packages (from delu) (2.5.1+cu124)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.21->delu) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.21->delu) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.21->delu) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.21->delu) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.21->delu) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.21->delu) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.9->delu) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.9->delu) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.9->delu) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.9->delu) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.9->delu) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.9->delu) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.9->delu) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.9->delu) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=1.9->delu)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=1.9->delu)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=1.9->delu)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=1.9->delu)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=1.9->delu)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=1.9->delu)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.9->delu) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.9->delu) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=1.9->delu)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.9->delu) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.9->delu) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=1.9->delu) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=1.9->delu) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.21->delu) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.21->delu) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.21->delu) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.21->delu) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.21->delu) (2024.2.0)\n",
      "Downloading delu-0.0.26-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, delu\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed delu-0.0.26 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (2.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (2024.2.0)\n",
      "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.7\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Collecting rtdl_num_embeddings\n",
      "  Downloading rtdl_num_embeddings-0.0.12-py3-none-any.whl.metadata (903 bytes)\n",
      "Requirement already satisfied: torch<3,>=1.12 in /usr/local/lib/python3.11/dist-packages (from rtdl_num_embeddings) (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=1.12->rtdl_num_embeddings) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=1.12->rtdl_num_embeddings) (3.0.2)\n",
      "Downloading rtdl_num_embeddings-0.0.12-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rtdl_num_embeddings\n",
      "Successfully installed rtdl_num_embeddings-0.0.12\n",
      "Cloning into 'testing-kan'...\n",
      "remote: Enumerating objects: 222, done.\u001b[K\n",
      "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
      "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
      "remote: Total 222 (delta 33), reused 0 (delta 0), pack-reused 161 (from 1)\u001b[K\n",
      "Receiving objects: 100% (222/222), 126.73 KiB | 6.67 MiB/s, done.\n",
      "Resolving deltas: 100% (113/113), done.\n"
     ]
    }
   ],
   "source": [
    "!pip install delu\n",
    "!pip install ucimlrepo\n",
    "!pip install gdown\n",
    "!pip install rtdl_num_embeddings\n",
    "!git clone https://github.com/gbulgakov/testing-kan.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:41:33.298793Z",
     "iopub.status.busy": "2025-04-14T21:41:33.298505Z",
     "iopub.status.idle": "2025-04-14T21:41:48.433872Z",
     "shell.execute_reply": "2025-04-14T21:41:48.433072Z",
     "shell.execute_reply.started": "2025-04-14T21:41:33.298764Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgbulgakov\u001b[0m (\u001b[33mgeorgy-bulgakov\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from typing import Literal, Optional\n",
    "from torch import Tensor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import rtdl_num_embeddings\n",
    "import delu\n",
    "from IPython.display import FileLink\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "wandb.login(key='')\n",
    "\n",
    "# наши импорты\n",
    "sys.path.append('/kaggle/working/testing-kan/')\n",
    "from optimizers.ademamix import AdEMAMix\n",
    "from models.efficient_kan import KAN\n",
    "from models.fastkan import FastKAN\n",
    "from utils import utils\n",
    "from models.prepare_model import model_init_preparation, ModelWithEmbedding, MLP\n",
    "from utils.tg_bot import send_telegram_file, send_telegram_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-14T21:41:54.010277Z",
     "iopub.status.busy": "2025-04-14T21:41:54.009568Z",
     "iopub.status.idle": "2025-04-14T21:42:06.911527Z",
     "shell.execute_reply": "2025-04-14T21:42:06.910371Z",
     "shell.execute_reply.started": "2025-04-14T21:41:54.010251Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1s0w7gnhiwBCkF49Wdi_cUDpUtXlz2_6q\n",
      "To: /kaggle/working/eye.zip\n",
      "100%|█████████████████████████████████████████| 534k/534k [00:00<00:00, 109MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1GOkNlinj4zHVSNKbqjN1rR4cvsAf2IgR\n",
      "To: /kaggle/working/churn.zip\n",
      "100%|█████████████████████████████████████████| 453k/453k [00:00<00:00, 111MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=11B-l4EasJkclK_Q-RBcxYfGJLSvz-v5c\n",
      "To: /kaggle/working/california.zip\n",
      "100%|████████████████████████████████████████| 591k/591k [00:00<00:00, 98.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "# !gdown 1xvRa_-OEeG6xNRYE5V5iAfTwyWM1NiLl # otto\n",
    "# !gdown 1tYyhbHdYs_8I9jvXznMoeUAfBzwitaax # house\n",
    "# !gdown 1hy1dOAL2SE-XZSuMcjLcVgml2CoYkF9q # higgs-small\n",
    "!gdown 1hr076cK9QFxH6YZRg5V4av-H7IAve59r # gesture\n",
    "# !gdown 1ZNScy5fgqtgudT6MZ4EjLt1nwdqirtmX # fb-comments\n",
    "!gdown 1s0w7gnhiwBCkF49Wdi_cUDpUtXlz2_6q # eye\n",
    "#!gdown 1T04iP04UGVo95Om84ww1Ed8AFNziOaeY # covtype\n",
    "!gdown 1GOkNlinj4zHVSNKbqjN1rR4cvsAf2IgR # churn\n",
    "!gdown 11B-l4EasJkclK_Q-RBcxYfGJLSvz-v5c # california\n",
    "!gdown 1p8uqDPMfRlFIc69m7iikS6wGkA6JGj1H # adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:44:17.704478Z",
     "iopub.status.busy": "2025-04-14T21:44:17.704198Z",
     "iopub.status.idle": "2025-04-14T21:44:17.709694Z",
     "shell.execute_reply": "2025-04-14T21:44:17.709083Z",
     "shell.execute_reply.started": "2025-04-14T21:44:17.704457Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATASETS = ['adult', 'california', 'churn', 'covtype', 'eye', 'fb-comments',\n",
    "           'gesture', 'higgs-small', 'house', 'microsoft', 'otto', 'santander']\n",
    "\n",
    "\n",
    "BATCH_SIZES = {'gesture' : 128, 'churn' : 128, 'california' : 256, 'house' : 256, 'adult' : 256, 'otto' : 512, \n",
    "               'higgs-small' : 512, 'fb-comments' : 512, 'santander' : 1024, 'covtype' : 1024, 'microsoft' : 1024, 'eye': 128}\n",
    "\n",
    "REGRESSION = ['house', 'fb-comments', 'microsoft', 'california']\n",
    "MULTICLASS = ['covtype', 'eye', 'gesture', 'otto']\n",
    "BINCLASS = ['adult', 'churn', 'higgs-small', 'santander']\n",
    "\n",
    "OPTIMIZERS = {'adamw' : torch.optim.AdamW,\n",
    "              'ademamix' : AdEMAMix\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:44:19.145959Z",
     "iopub.status.busy": "2025-04-14T21:44:19.145276Z",
     "iopub.status.idle": "2025-04-14T21:44:19.158474Z",
     "shell.execute_reply": "2025-04-14T21:44:19.157791Z",
     "shell.execute_reply.started": "2025-04-14T21:44:19.145931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torch.optim import AdamW, Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR, CosineAnnealingLR\n",
    "from torch.nn import MSELoss\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "\n",
    "def apply_model(batch: dict[str, Tensor], model) -> Tensor:\n",
    "    return model(batch['X_num'], batch.get('X_cat')).squeeze(-1)\n",
    "\n",
    "def train_epoch(model, device, dataset, loss_fn, optimizer, scheduler):\n",
    "\n",
    "    dataset_name = dataset['info']['id'].split('--')[0]\n",
    "    task_type = dataset['info']['task_type']\n",
    "    batch_size = BATCH_SIZES[dataset_name]\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    pred = []\n",
    "    gt = [] # настоящие таргеты\n",
    "    start_time = time.time()\n",
    "\n",
    "    for data in delu.iter_batches(dataset['train'], shuffle=True, batch_size=batch_size):\n",
    "        for key, tensor in data.items():\n",
    "            data[key] = tensor.to(device)\n",
    "        # обучение\n",
    "        optimizer.zero_grad()\n",
    "        output = apply_model(data, model)\n",
    "        if task_type == 'multiclass':\n",
    "            data['y'] = data['y'].long()\n",
    "        loss_value = loss_fn(output, data['y']) \n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        # сохранение истории\n",
    "        train_loss += loss_value.item()\n",
    "        if output.dim() > 1:\n",
    "            pred.append(output.argmax(1))\n",
    "        else:\n",
    "            pred.append(output >= 0.5)\n",
    "        gt.append(data['y'])\n",
    "    scheduler.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "\n",
    "    num_batches = dataset['train']['y'].shape[0] // batch_size + 1\n",
    "    pred = torch.cat(pred)\n",
    "    gt = torch.cat(gt)\n",
    "    train_accuracy = (pred == gt).float().mean().item()\n",
    "\n",
    "    return train_loss / num_batches, train_accuracy, epoch_time # с нормировкой\n",
    "    \n",
    "def validate(model, device, dataset, loss_fn, part='val'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    val_loss = 0.0\n",
    "\n",
    "    pred = []\n",
    "    gt = [] # настоящие таргеты\n",
    "\n",
    "    dataset_name = dataset['info']['id'].split('--')[0]\n",
    "    task_type = dataset['info']['task_type']\n",
    "    batch_size = BATCH_SIZES[dataset_name]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        for data in delu.iter_batches(dataset[part], shuffle=False, batch_size=batch_size):\n",
    "            for key, tensor in data.items():\n",
    "                data[key] = tensor.to(device)\n",
    "            output = apply_model(data, model)\n",
    "            if task_type == 'multiclass':\n",
    "                data['y'] = data['y'].long()\n",
    "            val_loss += loss_fn(output, data['y']).item()\n",
    "            if output.dim() > 1:\n",
    "                pred.append(output.argmax(1))\n",
    "            else:\n",
    "                pred.append(output >= 0.5)\n",
    "            gt.append(data['y'])\n",
    "        end_time = time.time()\n",
    "        val_time = end_time - start_time\n",
    "        \n",
    "\n",
    "    num_batches = dataset[part]['y'].shape[0] // batch_size + 1\n",
    "    pred = torch.cat(pred)\n",
    "    gt = torch.cat(gt)\n",
    "    val_accuracy = (pred == gt).float().mean().item()\n",
    "\n",
    "    return val_loss / num_batches, val_accuracy, val_time # с нормировкой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно ``model.to()`` лучше вызывать 1 раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:49:14.647180Z",
     "iopub.status.busy": "2025-04-14T21:49:14.646886Z",
     "iopub.status.idle": "2025-04-14T21:49:14.653990Z",
     "shell.execute_reply": "2025-04-14T21:49:14.653215Z",
     "shell.execute_reply.started": "2025-04-14T21:49:14.647159Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    epochs, model, model_name,\n",
    "    device, dataset, loss_fn,\n",
    "    optimizer\n",
    "):\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    model.to(device)\n",
    "    dataset_name = dataset['info']['id'].split('--')[0]\n",
    "    task_type = dataset['info']['task_type']\n",
    "    batch_size = BATCH_SIZES[dataset_name]\n",
    "\n",
    "    train_times = []\n",
    "    val_times = []\n",
    "    for epoch in tqdm(range(epochs), desc = f'{model_name} on {dataset_name}'):\n",
    "        train_loss, train_acc, train_time = train_epoch(model, device, dataset, loss_fn, optimizer, scheduler)\n",
    "        val_loss, val_acc, val_time = validate(model, device, dataset, loss_fn)\n",
    "\n",
    "        wandb.log({\n",
    "            'epoch' : epoch,\n",
    "            'train_loss' : train_loss,\n",
    "            'train_acc' : train_acc,\n",
    "            'val_loss' : val_loss,\n",
    "            'val_acc' : val_acc,\n",
    "            'lr' : scheduler.get_last_lr()[0]\n",
    "        })\n",
    "        train_times.append(train_time)\n",
    "        val_times.append(val_time)\n",
    "\n",
    "    # размерность входа backbone\n",
    "    in_features = dataset['train']['X_num'].shape[1]  # Количество числовых признаков\n",
    "    if 'X_cat' in dataset['train']:\n",
    "        in_features += dataset['train']['X_cat'].shape[1]  # Добавляем категориальные признаки\n",
    "\n",
    "    \n",
    "    wandb.log({\n",
    "        'train_epoch_time' : sum(train_times) / epochs,\n",
    "        'val_epoch_time' : sum(val_times) / epochs,\n",
    "        'num_params' : utils.count_parameters(model),\n",
    "        'in_features' : in_features,\n",
    "        'out_features' : (1 if task_type != 'multiclass' else dataset['info']['n_classes'])\n",
    "        # ширины и так будут залоггированы\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:44:23.418082Z",
     "iopub.status.busy": "2025-04-14T21:44:23.417631Z",
     "iopub.status.idle": "2025-04-14T21:44:23.421897Z",
     "shell.execute_reply": "2025-04-14T21:44:23.421178Z",
     "shell.execute_reply.started": "2025-04-14T21:44:23.418063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_optimizer(optim_name, model_params, config):\n",
    "    optim_class = OPTIMIZERS[optim_name]\n",
    "    optim_kwargs = {'lr' : config['lr']}\n",
    "    if optim_name != 'muon': # это на будущее\n",
    "        optim_kwargs['weight_decay'] = config['weight_decay']\n",
    "    return optim_class(model_params, **optim_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция тюнинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:49:23.046702Z",
     "iopub.status.busy": "2025-04-14T21:49:23.046416Z",
     "iopub.status.idle": "2025-04-14T21:49:23.054067Z",
     "shell.execute_reply": "2025-04-14T21:49:23.053341Z",
     "shell.execute_reply.started": "2025-04-14T21:49:23.046679Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def wandb_tuning(project_name, dataset_name, \n",
    "                 model_name, emb_name, optim_name, \n",
    "                 dataset, num_epochs=10, num_trials=70):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    dataset_info = dataset['info']\n",
    "    num_cont_cols = dataset['train']['X_num'].shape[1]\n",
    "    sweep_name = f'tuning {model_name}_{emb_name}_{optim_name} on {dataset_name}'\n",
    "\n",
    "    # просто оборачиваем нашу train\n",
    "    def sweep_wrapper():\n",
    "        with wandb.init(\n",
    "            project=f'{project_name}',\n",
    "            group=f'dataset_{dataset_name}',\n",
    "            tags=[f'model_{model_name}', f'emb_{emb_name}', f'optim_{optim_name}', f'dataset_{dataset_name}', 'tuning'],\n",
    "            config=sweep_config\n",
    "        ) as run:\n",
    "            config = wandb.config\n",
    "            _, backbone, bins, loss_fn = model_init_preparation(\n",
    "                config=config,\n",
    "                dataset=dataset,\n",
    "                model_name=model_name,\n",
    "                emb_name=emb_name\n",
    "            )\n",
    "            model = ModelWithEmbedding(\n",
    "                n_cont_features=num_cont_cols,\n",
    "                d_embedding=config.get('d_embedding', None),\n",
    "                emb_name=emb_name,\n",
    "                backbone_model=backbone,\n",
    "                bins=bins, \n",
    "                sigma=config.get('sigma', None)\n",
    "            )\n",
    "            train(\n",
    "                epochs=num_epochs,\n",
    "                model=model,\n",
    "                model_name=f'{model_name}_{emb_name}_{optim_name}',\n",
    "                device=device,\n",
    "                dataset=dataset,\n",
    "                loss_fn=loss_fn,\n",
    "                optimizer=get_optimizer(optim_name, model.parameters(), config),\n",
    "            )\n",
    "    sweep_config = utils.get_sweep_config(model_name, emb_name, dataset_info['task_type'], \n",
    "                                    f'tuning {model_name}_{emb_name}_{optim_name} on {dataset_name}')\n",
    "    \n",
    "    sweep_id = wandb.sweep(sweep=sweep_config,\n",
    "                           project=f'{project_name}',\n",
    "                           entity='georgy-bulgakov') \n",
    "    wandb.agent(sweep_id, sweep_wrapper, count=num_trials)\n",
    "    return sweep_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для тестирования на разных сидах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:54:01.820853Z",
     "iopub.status.busy": "2025-04-14T21:54:01.820598Z",
     "iopub.status.idle": "2025-04-14T21:54:01.833692Z",
     "shell.execute_reply": "2025-04-14T21:54:01.832901Z",
     "shell.execute_reply.started": "2025-04-14T21:54:01.820836Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_best_model(best_params, project_name, dataset_name, model_name, emb_name, optim_name, dataset, num_epochs=10):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    num_cont_cols = dataset['train']['X_num'].shape[1]\n",
    "    d_embedding = best_params.get('d_embedding', None)\n",
    "    sigma = best_params.get('sigma', None)\n",
    "\n",
    "    # подготовка логирования\n",
    "    test_accuracies = []\n",
    "    test_losses = []\n",
    "    test_times = []\n",
    "    train_times = []\n",
    "\n",
    "    testing_config = utils.get_test_config(dataset['info']['task_type'], \n",
    "                                     f'testing {model_name}_{emb_name}_{optim_name} on {dataset_name}')\n",
    "    # обертка тестирования\n",
    "    def test_wrapper():\n",
    "        with wandb.init(\n",
    "            project=f'{project_name}',\n",
    "            group=f'dataset_{dataset_name}',\n",
    "            tags=[f'model_{model_name}', f'emb_{emb_name}', f'optim_{optim_name}', f'dataset_{dataset_name}', 'testing'],\n",
    "            config=testing_config\n",
    "        ) as run:\n",
    "            config = wandb.config\n",
    "            # seed + подготовка модели\n",
    "            utils.seed_everything(config['seed'])\n",
    "            layers, backbone, bins, loss_fn = model_init_preparation(\n",
    "                config=best_params,\n",
    "                dataset=dataset,\n",
    "                model_name=model_name,\n",
    "                emb_name=emb_name\n",
    "            )\n",
    "            model = ModelWithEmbedding(\n",
    "                n_cont_features=num_cont_cols,\n",
    "                d_embedding=d_embedding,\n",
    "                emb_name=emb_name,\n",
    "                backbone_model=backbone,\n",
    "                bins=bins, \n",
    "                sigma=sigma\n",
    "            )\n",
    "\n",
    "            start_time = time.time()\n",
    "            train(\n",
    "                epochs=num_epochs,\n",
    "                model=model,\n",
    "                model_name=f'{model_name}_{emb_name}_{optim_name}',\n",
    "                device=device,\n",
    "                dataset=dataset,\n",
    "                loss_fn=loss_fn,\n",
    "                optimizer=get_optimizer(optim_name, model.parameters(), best_params)\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            test_loss, test_acc, test_time = validate(model, device, dataset, loss_fn, 'test')\n",
    "            # Логируем результаты для каждого сида\n",
    "            run.log({\n",
    "                'test_loss': test_loss,\n",
    "                'test_acc': test_acc,\n",
    "                'full_train_time': end_time - start_time,\n",
    "                'test_time': test_time,\n",
    "                'seed': config['seed']\n",
    "            })\n",
    "\n",
    "            test_accuracies.append(test_acc)\n",
    "            test_losses.append(np.sqrt(test_loss)) # переходим к RMSE\n",
    "            test_times.append(test_time)\n",
    "            train_times.append(end_time - start_time)\n",
    "\n",
    "    test_id = wandb.sweep(sweep=testing_config,\n",
    "                           project=f'{project_name}',\n",
    "                           entity='georgy-bulgakov') \n",
    "    wandb.agent(test_id, test_wrapper)\n",
    "\n",
    "    # Создаем финальный run для агрегированных результатов\n",
    "    with wandb.init(\n",
    "        project=f\"{project_name}\",\n",
    "        group=f'dataset_{dataset_name}',\n",
    "        name=\"aggregated_results\",\n",
    "        tags=[f'model_{model_name}', f'emb_{emb_name}', f'optim_{optim_name}', f'dataset_{dataset_name}', 'testing'],\n",
    "        config=best_params\n",
    "    ) as run:\n",
    "        stats = {\n",
    "            'model' : f'{model_name}_{emb_name}_{optim_name}',\n",
    "            'mean_test_acc': np.mean(test_accuracies),\n",
    "            'std_test_acc': np.std(test_accuracies),\n",
    "            'mean_test_loss': np.mean(test_losses),\n",
    "            'std_test_loss': np.std(test_losses),\n",
    "            'mean_test_time': np.mean(test_times),\n",
    "            'mean_train_time': np.mean(train_times),\n",
    "            'all_test_accs': test_accuracies,\n",
    "            'all_test_losses': test_losses,\n",
    "            'all_test_times': test_times,\n",
    "            'all_train_times': train_times\n",
    "        }\n",
    "        \n",
    "        run.log(stats)\n",
    "        stats['name'] = f'{model_name}_{emb_name}_{optim_name}'\n",
    "        \n",
    "    keys = ['model', 'mean_test_acc', 'std_test_acc', 'mean_test_loss', 'std_test_loss', 'mean_test_time', 'mean_train_time']\n",
    "    return {key : stats[key] for key in keys} # чисто технически для удобства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:48:10.375994Z",
     "iopub.status.busy": "2025-04-14T21:48:10.375652Z",
     "iopub.status.idle": "2025-04-14T21:48:10.381636Z",
     "shell.execute_reply": "2025-04-14T21:48:10.380954Z",
     "shell.execute_reply.started": "2025-04-14T21:48:10.375970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "def run_single_model(project_name, dataset_name, model_name, emb_name, optim_name, dataset, num_epochs, num_trials):\n",
    "    sweep_id = wandb_tuning(project_name, dataset_name, model_name, emb_name, optim_name, dataset, num_epochs, num_trials)\n",
    "    clear_output(wait=True)\n",
    "    # вспоминаем лучшие параметры\n",
    "    api = wandb.Api()\n",
    "    sweep = api.sweep(f'georgy-bulgakov/{project_name}/{sweep_id}')\n",
    "    runs = sweep.runs\n",
    "    best_run = None\n",
    "    if dataset['info']['task_type'] == 'regression':\n",
    "        best_run = min(runs, key=lambda run : run.summary.get('val_loss'))\n",
    "    else:\n",
    "        best_run = max(runs, key=lambda run : run.summary.get('val_acc'))\n",
    "    best_params = best_run.config\n",
    "    \n",
    "    stats = test_best_model(best_params, project_name, dataset_name, model_name, emb_name, optim_name, dataset, num_epochs)\n",
    "    return stats, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:47:45.157406Z",
     "iopub.status.busy": "2025-04-14T21:47:45.156799Z",
     "iopub.status.idle": "2025-04-14T21:47:45.163661Z",
     "shell.execute_reply": "2025-04-14T21:47:45.162869Z",
     "shell.execute_reply.started": "2025-04-14T21:47:45.157380Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "def run_single_dataset(project_name, dataset_name, \n",
    "                       optim_names, emb_names, model_names, \n",
    "                       num_epochs, num_trials):\n",
    "    # dataset_type = dataset_info['type']\n",
    "    dataset = utils.load_dataset(dataset_name)\n",
    "    results = []\n",
    "    pkl_logs = {}\n",
    "\n",
    "    for model_name in model_names: # можно оставить только kan, тогда model_names = ['kan']\n",
    "        for optim_name in optim_names:\n",
    "            for emb_name in emb_names:\n",
    "                stats, best_params = run_single_model(project_name, dataset_name, model_name, emb_name, optim_name, dataset, num_epochs, num_trials)\n",
    "                results.append(stats)\n",
    "                clear_output(wait=True)\n",
    "                pkl_logs[f'{model_name}_{emb_name}_{optim_name}'] = (stats | best_params)\n",
    "                send_telegram_message(f'✅ {model_name}_{emb_name}_{optim_name} finished on {dataset_name}')\n",
    "\n",
    "    \n",
    "    with wandb.init(\n",
    "        project=project_name,\n",
    "        group=f'dataset_{dataset_name}',\n",
    "        name='models_comparison'\n",
    "    ) as run:\n",
    "        run.log({\n",
    "            f'final_table_{dataset_name}' : wandb.Table(dataframe=pd.DataFrame(results))\n",
    "        })\n",
    "\n",
    "    with open(f'/kaggle/working/{dataset_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(pkl_logs, f)\n",
    "\n",
    "    send_telegram_file(f'{dataset_name}.pkl')\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:55:24.314648Z",
     "iopub.status.busy": "2025-04-14T21:55:24.314396Z",
     "iopub.status.idle": "2025-04-14T21:59:20.442027Z",
     "shell.execute_reply": "2025-04-14T21:59:20.440952Z",
     "shell.execute_reply.started": "2025-04-14T21:55:24.314631Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: q1jdy35i\n",
      "Sweep URL: https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/sweeps/q1jdy35i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fukxykuh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'TAB-KAN study' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250414_215851-fukxykuh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/fukxykuh' target=\"_blank\">denim-sweep-1</a></strong> to <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/sweeps/q1jdy35i' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/sweeps/q1jdy35i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/sweeps/q1jdy35i' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/sweeps/q1jdy35i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/fukxykuh' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/fukxykuh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kan_mlp_periodic_ademamix on churn: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>full_train_time</td><td>▁</td></tr><tr><td>in_features</td><td>▁</td></tr><tr><td>lr</td><td>▁</td></tr><tr><td>num_params</td><td>▁</td></tr><tr><td>out_features</td><td>▁</td></tr><tr><td>seed</td><td>▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_time</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_epoch_time</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_epoch_time</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>full_train_time</td><td>0.46855</td></tr><tr><td>in_features</td><td>13</td></tr><tr><td>lr</td><td>0</td></tr><tr><td>num_params</td><td>105615</td></tr><tr><td>out_features</td><td>1</td></tr><tr><td>seed</td><td>0</td></tr><tr><td>test_acc</td><td>0.7965</td></tr><tr><td>test_loss</td><td>0.69181</td></tr><tr><td>test_time</td><td>0.03831</td></tr><tr><td>train_acc</td><td>0.79641</td></tr><tr><td>train_epoch_time</td><td>0.43148</td></tr><tr><td>train_loss</td><td>0.68707</td></tr><tr><td>val_acc</td><td>0.79625</td></tr><tr><td>val_epoch_time</td><td>0.02863</td></tr><tr><td>val_loss</td><td>0.69275</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">denim-sweep-1</strong> at: <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/fukxykuh' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/fukxykuh</a><br> View project at: <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250414_215851-fukxykuh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gkuyhjsk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'TAB-KAN study' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250414_215907-gkuyhjsk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/gkuyhjsk' target=\"_blank\">lunar-sweep-2</a></strong> to <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/sweeps/q1jdy35i' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/sweeps/q1jdy35i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/sweeps/q1jdy35i' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/sweeps/q1jdy35i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/gkuyhjsk' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/gkuyhjsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kan_mlp_periodic_ademamix on churn: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>full_train_time</td><td>▁</td></tr><tr><td>in_features</td><td>▁</td></tr><tr><td>lr</td><td>▁</td></tr><tr><td>num_params</td><td>▁</td></tr><tr><td>out_features</td><td>▁</td></tr><tr><td>seed</td><td>▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_time</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_epoch_time</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_epoch_time</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>full_train_time</td><td>0.45447</td></tr><tr><td>in_features</td><td>13</td></tr><tr><td>lr</td><td>0</td></tr><tr><td>num_params</td><td>105615</td></tr><tr><td>out_features</td><td>1</td></tr><tr><td>seed</td><td>1</td></tr><tr><td>test_acc</td><td>0.7965</td></tr><tr><td>test_loss</td><td>0.6919</td></tr><tr><td>test_time</td><td>0.03265</td></tr><tr><td>train_acc</td><td>0.79656</td></tr><tr><td>train_epoch_time</td><td>0.41883</td></tr><tr><td>train_loss</td><td>0.68672</td></tr><tr><td>val_acc</td><td>0.79625</td></tr><tr><td>val_epoch_time</td><td>0.02691</td></tr><tr><td>val_loss</td><td>0.69157</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lunar-sweep-2</strong> at: <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/gkuyhjsk' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/gkuyhjsk</a><br> View project at: <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250414_215907-gkuyhjsk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7wb8l5be with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/3186385077.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'churn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'california'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eye'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mrun_single_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_31/906778152.py\u001b[0m in \u001b[0;36mrun_single_dataset\u001b[0;34m(project_name, dataset_name, optim_names, emb_names, model_names, num_epochs, num_trials)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moptim_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptim_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0memb_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memb_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_single_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/2893983733.py\u001b[0m in \u001b[0;36mrun_single_model\u001b[0;34m(project_name, dataset_name, model_name, emb_name, optim_name, dataset, num_epochs, num_trials)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/3536343468.py\u001b[0m in \u001b[0;36mtest_best_model\u001b[0;34m(best_params, project_name, dataset_name, model_name, emb_name, optim_name, dataset, num_epochs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# Создаем финальный run для агрегированных результатов\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     with wandb.init(\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{project_name}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'dataset_{dataset_name}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         \u001b[0mwl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_telemetry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \"\"\"\n\u001b[0;32m--> 371\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36m_setup\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0m_singleton\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbSetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pid, settings, environ)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_EarlyLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtermsetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36m_settings_setup\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# infer settings from the system environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_from_system_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# load SageMaker settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_settings.py\u001b[0m in \u001b[0;36mupdate_from_system_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[0;31m# Attempt to get notebook information if not already set by the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jupyter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m             \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjupyter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_jupyter_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_jupyter_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mnotebook_metadata\u001b[0;34m(silent)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# Colab:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# request the most recent contents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mipynb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattempt_colab_load_ipynb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mipynb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mjupyter_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             return {\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mattempt_colab_load_ipynb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# This isn't thread safe, never call in a thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get_ipynb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ipynb\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'TAB-KAN study' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250414_215922-7wb8l5be</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/7wb8l5be' target=\"_blank\">glad-sweep-3</a></strong> to <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/sweeps/q1jdy35i' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/sweeps/q1jdy35i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/sweeps/q1jdy35i' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/sweeps/q1jdy35i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/7wb8l5be' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/7wb8l5be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kan_mlp_periodic_ademamix on churn: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>full_train_time</td><td>▁</td></tr><tr><td>in_features</td><td>▁</td></tr><tr><td>lr</td><td>▁</td></tr><tr><td>num_params</td><td>▁</td></tr><tr><td>out_features</td><td>▁</td></tr><tr><td>seed</td><td>▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_time</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_epoch_time</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_epoch_time</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>full_train_time</td><td>0.4542</td></tr><tr><td>in_features</td><td>13</td></tr><tr><td>lr</td><td>0</td></tr><tr><td>num_params</td><td>105615</td></tr><tr><td>out_features</td><td>1</td></tr><tr><td>seed</td><td>2</td></tr><tr><td>test_acc</td><td>0.7965</td></tr><tr><td>test_loss</td><td>0.64697</td></tr><tr><td>test_time</td><td>0.03375</td></tr><tr><td>train_acc</td><td>0.79625</td></tr><tr><td>train_epoch_time</td><td>0.41823</td></tr><tr><td>train_loss</td><td>0.64177</td></tr><tr><td>val_acc</td><td>0.79625</td></tr><tr><td>val_epoch_time</td><td>0.02717</td></tr><tr><td>val_loss</td><td>0.64795</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glad-sweep-3</strong> at: <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/7wb8l5be' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study/runs/7wb8l5be</a><br> View project at: <a href='https://wandb.ai/georgy-bulgakov/TAB-KAN%20study' target=\"_blank\">https://wandb.ai/georgy-bulgakov/TAB-KAN%20study</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250414_215922-7wb8l5be/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim_names = ['ademamix']\n",
    "model_names = ['fast_kan']\n",
    "emb_names = ['none', 'periodic']\n",
    "project_name = 'TAB-KAN study'\n",
    "\n",
    "for dataset_name in ['churn', 'california']:\n",
    "    run_single_dataset(project_name, dataset_name, optim_names, emb_names, model_names, 10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
